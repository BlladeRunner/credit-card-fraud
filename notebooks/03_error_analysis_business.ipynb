{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "356baf12",
   "metadata": {},
   "source": [
    "# Notebook 03 — Error Analysis & Business Impact\n",
    "\n",
    "Goal:\n",
    "- Inspect false positives / false negatives at the chosen threshold\n",
    "- Understand patterns behind model errors\n",
    "- Translate metrics into business terms (review load, missed fraud loss)\n",
    "- Produce decision-ready recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.config import CFG\n",
    "from src.io import load_csv\n",
    "from src.split import stratified_split\n",
    "from src.models import train_logreg_baseline\n",
    "from src.thresholding import find_threshold_min_cost, apply_threshold\n",
    "from src.evaluation import evaluate_at_threshold\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/raw/creditcard.csv\"\n",
    "df = load_csv(DATA_PATH)\n",
    "\n",
    "target_col = CFG.target_col\n",
    "\n",
    "train_df, test_df = stratified_split(\n",
    "    df=df,\n",
    "    target_col=target_col,\n",
    "    test_size=CFG.test_size,\n",
    "    seed=CFG.seed,\n",
    ")\n",
    "\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "y_train = train_df[target_col].values\n",
    "\n",
    "X_test = test_df.drop(columns=[target_col])\n",
    "y_test = test_df[target_col].values\n",
    "\n",
    "trained = train_logreg_baseline(X_train, y_train, seed=CFG.seed)\n",
    "y_prob = trained.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe0c68",
   "metadata": {},
   "source": [
    "## Threshold selection\n",
    "\n",
    "We analyze errors under a business-driven threshold.\n",
    "Here we use the **minimum expected cost** threshold based on FN/FP costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43078d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = find_threshold_min_cost(\n",
    "    y_true=y_test,\n",
    "    y_prob=y_prob,\n",
    "    cost_fn=CFG.cost_false_negative,\n",
    "    cost_fp=CFG.cost_false_positive,\n",
    ")\n",
    "\n",
    "metrics = evaluate_at_threshold(\n",
    "    y_true=y_test,\n",
    "    y_prob=y_prob,\n",
    "    threshold=t,\n",
    "    cost_fn=CFG.cost_false_negative,\n",
    "    cost_fp=CFG.cost_false_positive,\n",
    ")\n",
    "\n",
    "t, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16af9e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = apply_threshold(y_prob, t)\n",
    "\n",
    "analysis_df = test_df.copy()\n",
    "analysis_df[\"y_true\"] = y_test\n",
    "analysis_df[\"y_prob\"] = y_prob\n",
    "analysis_df[\"y_pred\"] = y_pred\n",
    "\n",
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16573a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.array(metrics[\"TN_FP_FN_TP\"]) if \"TN_FP_FN_TP\" in metrics else None\n",
    "# if not present, compute quickly:\n",
    "if cm is None:\n",
    "    # metrics[\"confusion_matrix\"] exists as [[TN, FP],[FN, TP]]\n",
    "    m = np.array(metrics[\"confusion_matrix\"])\n",
    "    tn, fp, fn, tp = m[0,0], m[0,1], m[1,0], m[1,1]\n",
    "else:\n",
    "    tn, fp, fn, tp = cm\n",
    "\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac235406",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df = analysis_df[(analysis_df[\"y_true\"] == 0) & (analysis_df[\"y_pred\"] == 1)]\n",
    "fn_df = analysis_df[(analysis_df[\"y_true\"] == 1) & (analysis_df[\"y_pred\"] == 0)]\n",
    "tp_df = analysis_df[(analysis_df[\"y_true\"] == 1) & (analysis_df[\"y_pred\"] == 1)]\n",
    "tn_df = analysis_df[(analysis_df[\"y_true\"] == 0) & (analysis_df[\"y_pred\"] == 0)]\n",
    "\n",
    "len(fp_df), len(fn_df), len(tp_df), len(tn_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cdbdec",
   "metadata": {},
   "source": [
    "## Error patterns\n",
    "\n",
    "Because features V1–V28 are PCA-transformed and not interpretable, we focus on:\n",
    "- Amount patterns (transaction size)\n",
    "- probability distributions (model confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"group\": [\"TP\", \"FN\", \"FP\", \"TN\"],\n",
    "    \"count\": [len(tp_df), len(fn_df), len(fp_df), len(tn_df)],\n",
    "    \"amount_mean\": [tp_df[\"Amount\"].mean(), fn_df[\"Amount\"].mean(), fp_df[\"Amount\"].mean(), tn_df[\"Amount\"].mean()],\n",
    "    \"amount_median\": [tp_df[\"Amount\"].median(), fn_df[\"Amount\"].median(), fp_df[\"Amount\"].median(), tn_df[\"Amount\"].median()],\n",
    "    \"prob_mean\": [tp_df[\"y_prob\"].mean(), fn_df[\"y_prob\"].mean(), fp_df[\"y_prob\"].mean(), tn_df[\"y_prob\"].mean()],\n",
    "})\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fp_df[\"Amount\"], bins=50, alpha=0.7, label=\"FP\")\n",
    "plt.hist(fn_df[\"Amount\"], bins=50, alpha=0.7, label=\"FN\")\n",
    "plt.title(\"Amount distribution: False Positives vs False Negatives\")\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19bde08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fp_df[\"y_prob\"], bins=50, alpha=0.7, label=\"FP\")\n",
    "plt.hist(fn_df[\"y_prob\"], bins=50, alpha=0.7, label=\"FN\")\n",
    "plt.title(\"Model confidence for errors\")\n",
    "plt.xlabel(\"Predicted probability (fraud)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a609a501",
   "metadata": {},
   "source": [
    "## Business impact\n",
    "\n",
    "We translate confusion matrix into business terms:\n",
    "- FP → manual review load / customer friction\n",
    "- FN → missed fraud loss\n",
    "\n",
    "We use simplified cost assumptions from `CFG`:\n",
    "- cost_false_negative\n",
    "- cost_false_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35af3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_fn = CFG.cost_false_negative\n",
    "cost_fp = CFG.cost_false_positive\n",
    "\n",
    "expected_review_cost = fp * cost_fp\n",
    "expected_missed_fraud_cost = fn * cost_fn\n",
    "total_expected_cost = expected_review_cost + expected_missed_fraud_cost\n",
    "\n",
    "expected_review_cost, expected_missed_fraud_cost, total_expected_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea88728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_table = pd.DataFrame([\n",
    "    {\"item\": \"False Positives (alerts)\", \"count\": int(fp), \"unit_cost\": cost_fp, \"estimated_cost\": expected_review_cost},\n",
    "    {\"item\": \"False Negatives (missed fraud)\", \"count\": int(fn), \"unit_cost\": cost_fn, \"estimated_cost\": expected_missed_fraud_cost},\n",
    "])\n",
    "\n",
    "business_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe47178",
   "metadata": {},
   "source": [
    "## Decision-ready conclusion\n",
    "\n",
    "- Selected threshold: **T = {T}**\n",
    "- Under this threshold:\n",
    "  - Alerts (FP): **{FP}**\n",
    "  - Missed fraud (FN): **{FN}**\n",
    "  - Estimated review cost: **{REV_COST}**\n",
    "  - Estimated missed-fraud cost: **{FRAUD_COST}**\n",
    "  - Total expected cost: **{TOTAL}**\n",
    "\n",
    "### Recommendation\n",
    "- Use this threshold if the business prioritizes (cost minimization / recall / precision).\n",
    "- If alert volume is too high, increase threshold or add a second-stage model.\n",
    "- If missed fraud is too costly, lower threshold and accept higher review load.\n",
    "\n",
    "### Next steps\n",
    "- Try stronger models (e.g. Gradient Boosting) and compare PR-AUC + cost curves\n",
    "- Probability calibration (Platt/Isotonic) to make thresholds more reliable\n",
    "- Monitoring plan: weekly alert rate, drift checks, PR-AUC on labeled data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
